job ID             2952025
job Nodes      cs-4090-09

/home/golyuval/.local/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Loading tokenizer...
Map:   0%|          | 0/36718 [00:00<?, ? examples/s]Map:   3%|â–Ž         | 1000/36718 [00:00<00:13, 2566.30 examples/s]Map:   5%|â–Œ         | 2000/36718 [00:00<00:09, 3802.07 examples/s]Map:  11%|â–ˆ         | 4000/36718 [00:00<00:06, 5406.09 examples/s]Map:  14%|â–ˆâ–Ž        | 5000/36718 [00:01<00:06, 4618.81 examples/s]Map:  19%|â–ˆâ–‰        | 7000/36718 [00:01<00:04, 6164.53 examples/s]Map:  22%|â–ˆâ–ˆâ–       | 8000/36718 [00:01<00:05, 4881.37 examples/s]Map:  25%|â–ˆâ–ˆâ–       | 9000/36718 [00:02<00:06, 3971.21 examples/s]Map:  27%|â–ˆâ–ˆâ–‹       | 10000/36718 [00:02<00:05, 4611.64 examples/s]Map:  30%|â–ˆâ–ˆâ–‰       | 11000/36718 [00:02<00:05, 4955.00 examples/s]Map:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 13000/36718 [00:02<00:03, 6289.41 examples/s]Map:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 15000/36718 [00:02<00:03, 7104.23 examples/s]Map:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 16000/36718 [00:04<00:11, 1867.44 examples/s]Map:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17000/36718 [00:05<00:09, 2102.05 examples/s]Map:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 18000/36718 [00:05<00:07, 2469.85 examples/s]Map:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 20000/36718 [00:05<00:04, 3578.92 examples/s]Map:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 21000/36718 [00:05<00:04, 3819.46 examples/s]Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 22000/36718 [00:07<00:08, 1718.99 examples/s]Map:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 24000/36718 [00:07<00:04, 2597.92 examples/s]Map:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 25000/36718 [00:07<00:03, 3048.26 examples/s]Map:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 26000/36718 [00:07<00:03, 3116.83 examples/s]Map:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 27000/36718 [00:07<00:02, 3787.79 examples/s]Map:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 28000/36718 [00:09<00:06, 1412.64 examples/s]Map:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30000/36718 [00:09<00:02, 2310.89 examples/s]Map:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 31000/36718 [00:10<00:02, 2445.53 examples/s]Map:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 32000/36718 [00:12<00:03, 1333.72 examples/s]Map:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 34000/36718 [00:12<00:01, 2090.16 examples/s]Map:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 35000/36718 [00:12<00:00, 2548.14 examples/s]Map:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 36000/36718 [00:12<00:00, 3056.27 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36718/36718 [00:20<00:00, 1770.15 examples/s]
/home/golyuval/.local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
Loading Llama 3.1 Instruct 8B model in 8-bit precision...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [03:51<11:35, 231.78s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [07:35<07:34, 227.31s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [10:56<03:35, 215.04s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [11:23<00:00, 140.85s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [11:23<00:00, 170.88s/it]
/home/golyuval/.local/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/golyuval/.local/lib/python3.11/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-67e9c233-799be6c43f415ed00813d9cd;5c359c19-af6e-489a-be33-96f52e08845f)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.1-8B-Instruct.
  warnings.warn(
/home/golyuval/.local/lib/python3.11/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in meta-llama/Llama-3.1-8B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
Starting LoRA fine-tuning on Llama 3.1 Instruct 8B model ...
Saving LoRA adapter to ./Versions/alpha_test ...
