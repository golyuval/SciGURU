{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9998365924069939,
  "eval_steps": 500,
  "global_step": 4589,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0021787679067487337,
      "grad_norm": NaN,
      "learning_rate": 9.98256700806276e-05,
      "loss": 2.4872,
      "step": 10
    },
    {
      "epoch": 0.004357535813497467,
      "grad_norm": 1.766768217086792,
      "learning_rate": 9.962954892133363e-05,
      "loss": 2.8635,
      "step": 20
    },
    {
      "epoch": 0.006536303720246201,
      "grad_norm": 2.0673935413360596,
      "learning_rate": 9.941163652211811e-05,
      "loss": 2.3922,
      "step": 30
    },
    {
      "epoch": 0.008715071626994935,
      "grad_norm": 2.841111421585083,
      "learning_rate": 9.91937241229026e-05,
      "loss": 2.6045,
      "step": 40
    },
    {
      "epoch": 0.010893839533743668,
      "grad_norm": 2.995732545852661,
      "learning_rate": 9.897581172368708e-05,
      "loss": 2.2527,
      "step": 50
    },
    {
      "epoch": 0.013072607440492401,
      "grad_norm": 6.485256195068359,
      "learning_rate": 9.875789932447157e-05,
      "loss": 2.3756,
      "step": 60
    },
    {
      "epoch": 0.015251375347241134,
      "grad_norm": 5.896780490875244,
      "learning_rate": 9.853998692525605e-05,
      "loss": 2.2357,
      "step": 70
    },
    {
      "epoch": 0.01743014325398987,
      "grad_norm": 1.7235485315322876,
      "learning_rate": 9.832207452604054e-05,
      "loss": 2.1814,
      "step": 80
    },
    {
      "epoch": 0.019608911160738603,
      "grad_norm": 2.033947467803955,
      "learning_rate": 9.810416212682502e-05,
      "loss": 2.1828,
      "step": 90
    },
    {
      "epoch": 0.021787679067487336,
      "grad_norm": 2.659797430038452,
      "learning_rate": 9.78862497276095e-05,
      "loss": 2.3598,
      "step": 100
    },
    {
      "epoch": 0.02396644697423607,
      "grad_norm": 2.970676898956299,
      "learning_rate": 9.766833732839399e-05,
      "loss": 2.1887,
      "step": 110
    },
    {
      "epoch": 0.026145214880984802,
      "grad_norm": 2.685371160507202,
      "learning_rate": 9.745042492917847e-05,
      "loss": 2.3264,
      "step": 120
    },
    {
      "epoch": 0.028323982787733536,
      "grad_norm": 2.9246935844421387,
      "learning_rate": 9.723251252996296e-05,
      "loss": 2.2069,
      "step": 130
    },
    {
      "epoch": 0.03050275069448227,
      "grad_norm": 4.742886066436768,
      "learning_rate": 9.701460013074744e-05,
      "loss": 2.2974,
      "step": 140
    },
    {
      "epoch": 0.032681518601231,
      "grad_norm": 1.6368085145950317,
      "learning_rate": 9.679668773153193e-05,
      "loss": 2.1577,
      "step": 150
    },
    {
      "epoch": 0.03486028650797974,
      "grad_norm": 2.107471227645874,
      "learning_rate": 9.657877533231641e-05,
      "loss": 2.3311,
      "step": 160
    },
    {
      "epoch": 0.03703905441472847,
      "grad_norm": 2.022104501724243,
      "learning_rate": 9.636086293310089e-05,
      "loss": 2.1442,
      "step": 170
    },
    {
      "epoch": 0.039217822321477205,
      "grad_norm": 3.0569584369659424,
      "learning_rate": 9.614295053388538e-05,
      "loss": 2.2525,
      "step": 180
    },
    {
      "epoch": 0.041396590228225935,
      "grad_norm": 1.5006330013275146,
      "learning_rate": 9.592503813466986e-05,
      "loss": 2.2623,
      "step": 190
    },
    {
      "epoch": 0.04357535813497467,
      "grad_norm": 2.1592650413513184,
      "learning_rate": 9.570712573545435e-05,
      "loss": 2.1748,
      "step": 200
    },
    {
      "epoch": 0.04575412604172341,
      "grad_norm": 1.6102715730667114,
      "learning_rate": 9.548921333623883e-05,
      "loss": 2.1153,
      "step": 210
    },
    {
      "epoch": 0.04793289394847214,
      "grad_norm": 2.273754358291626,
      "learning_rate": 9.527130093702332e-05,
      "loss": 2.2413,
      "step": 220
    },
    {
      "epoch": 0.050111661855220875,
      "grad_norm": 1.643115758895874,
      "learning_rate": 9.50533885378078e-05,
      "loss": 2.1816,
      "step": 230
    },
    {
      "epoch": 0.052290429761969605,
      "grad_norm": 3.0294735431671143,
      "learning_rate": 9.48354761385923e-05,
      "loss": 2.0994,
      "step": 240
    },
    {
      "epoch": 0.05446919766871834,
      "grad_norm": 1.3489162921905518,
      "learning_rate": 9.461756373937679e-05,
      "loss": 2.1563,
      "step": 250
    },
    {
      "epoch": 0.05664796557546707,
      "grad_norm": 1.2072243690490723,
      "learning_rate": 9.439965134016125e-05,
      "loss": 2.2094,
      "step": 260
    },
    {
      "epoch": 0.05882673348221581,
      "grad_norm": 1.6412599086761475,
      "learning_rate": 9.418173894094574e-05,
      "loss": 2.1043,
      "step": 270
    },
    {
      "epoch": 0.06100550138896454,
      "grad_norm": 1.098628044128418,
      "learning_rate": 9.396382654173022e-05,
      "loss": 2.0678,
      "step": 280
    },
    {
      "epoch": 0.06318426929571327,
      "grad_norm": 2.2321856021881104,
      "learning_rate": 9.374591414251471e-05,
      "loss": 2.1629,
      "step": 290
    },
    {
      "epoch": 0.065363037202462,
      "grad_norm": 1.2049682140350342,
      "learning_rate": 9.352800174329919e-05,
      "loss": 1.9703,
      "step": 300
    },
    {
      "epoch": 0.06754180510921075,
      "grad_norm": 3.235144853591919,
      "learning_rate": 9.331008934408369e-05,
      "loss": 2.128,
      "step": 310
    },
    {
      "epoch": 0.06972057301595948,
      "grad_norm": 1.6170930862426758,
      "learning_rate": 9.309217694486816e-05,
      "loss": 2.2116,
      "step": 320
    },
    {
      "epoch": 0.07189934092270821,
      "grad_norm": 3.6315767765045166,
      "learning_rate": 9.287426454565266e-05,
      "loss": 2.2837,
      "step": 330
    },
    {
      "epoch": 0.07407810882945694,
      "grad_norm": 1.4025452136993408,
      "learning_rate": 9.265635214643715e-05,
      "loss": 2.1149,
      "step": 340
    },
    {
      "epoch": 0.07625687673620568,
      "grad_norm": 1.6083253622055054,
      "learning_rate": 9.243843974722161e-05,
      "loss": 2.1614,
      "step": 350
    },
    {
      "epoch": 0.07843564464295441,
      "grad_norm": 3.6303870677948,
      "learning_rate": 9.22205273480061e-05,
      "loss": 2.2152,
      "step": 360
    },
    {
      "epoch": 0.08061441254970314,
      "grad_norm": 1.7536890506744385,
      "learning_rate": 9.200261494879058e-05,
      "loss": 2.1519,
      "step": 370
    },
    {
      "epoch": 0.08279318045645187,
      "grad_norm": 4.423275947570801,
      "learning_rate": 9.178470254957508e-05,
      "loss": 2.15,
      "step": 380
    },
    {
      "epoch": 0.08497194836320061,
      "grad_norm": 3.0629515647888184,
      "learning_rate": 9.156679015035955e-05,
      "loss": 2.1497,
      "step": 390
    },
    {
      "epoch": 0.08715071626994934,
      "grad_norm": 1.457615852355957,
      "learning_rate": 9.134887775114405e-05,
      "loss": 2.1514,
      "step": 400
    },
    {
      "epoch": 0.08932948417669807,
      "grad_norm": 1.4441784620285034,
      "learning_rate": 9.113096535192854e-05,
      "loss": 2.1483,
      "step": 410
    },
    {
      "epoch": 0.09150825208344682,
      "grad_norm": 1.3547582626342773,
      "learning_rate": 9.091305295271302e-05,
      "loss": 2.1039,
      "step": 420
    },
    {
      "epoch": 0.09368701999019555,
      "grad_norm": 1.9869498014450073,
      "learning_rate": 9.06951405534975e-05,
      "loss": 2.1973,
      "step": 430
    },
    {
      "epoch": 0.09586578789694428,
      "grad_norm": 1.5306038856506348,
      "learning_rate": 9.047722815428197e-05,
      "loss": 2.2079,
      "step": 440
    },
    {
      "epoch": 0.098044555803693,
      "grad_norm": 2.199954032897949,
      "learning_rate": 9.025931575506647e-05,
      "loss": 2.1839,
      "step": 450
    },
    {
      "epoch": 0.10022332371044175,
      "grad_norm": 2.7900683879852295,
      "learning_rate": 9.004140335585094e-05,
      "loss": 2.0429,
      "step": 460
    },
    {
      "epoch": 0.10240209161719048,
      "grad_norm": 2.696075439453125,
      "learning_rate": 8.982349095663544e-05,
      "loss": 2.1391,
      "step": 470
    },
    {
      "epoch": 0.10458085952393921,
      "grad_norm": 1.5517255067825317,
      "learning_rate": 8.960557855741993e-05,
      "loss": 2.3312,
      "step": 480
    },
    {
      "epoch": 0.10675962743068794,
      "grad_norm": 2.3765525817871094,
      "learning_rate": 8.938766615820441e-05,
      "loss": 2.2091,
      "step": 490
    },
    {
      "epoch": 0.10893839533743668,
      "grad_norm": 4.392302513122559,
      "learning_rate": 8.91697537589889e-05,
      "loss": 2.1758,
      "step": 500
    },
    {
      "epoch": 0.11111716324418541,
      "grad_norm": 2.8676083087921143,
      "learning_rate": 8.895184135977338e-05,
      "loss": 2.1189,
      "step": 510
    },
    {
      "epoch": 0.11329593115093414,
      "grad_norm": 2.8683483600616455,
      "learning_rate": 8.873392896055786e-05,
      "loss": 2.1719,
      "step": 520
    },
    {
      "epoch": 0.11547469905768289,
      "grad_norm": 2.25797700881958,
      "learning_rate": 8.851601656134234e-05,
      "loss": 2.2611,
      "step": 530
    },
    {
      "epoch": 0.11765346696443162,
      "grad_norm": 1.5956536531448364,
      "learning_rate": 8.829810416212683e-05,
      "loss": 2.0908,
      "step": 540
    },
    {
      "epoch": 0.11983223487118035,
      "grad_norm": 2.5307469367980957,
      "learning_rate": 8.80801917629113e-05,
      "loss": 2.2299,
      "step": 550
    },
    {
      "epoch": 0.12201100277792908,
      "grad_norm": 2.008409023284912,
      "learning_rate": 8.78622793636958e-05,
      "loss": 2.1392,
      "step": 560
    },
    {
      "epoch": 0.12418977068467782,
      "grad_norm": 1.902055025100708,
      "learning_rate": 8.764436696448029e-05,
      "loss": 2.2758,
      "step": 570
    },
    {
      "epoch": 0.12636853859142655,
      "grad_norm": 1.968813180923462,
      "learning_rate": 8.742645456526477e-05,
      "loss": 2.1244,
      "step": 580
    },
    {
      "epoch": 0.12854730649817528,
      "grad_norm": 2.137833595275879,
      "learning_rate": 8.720854216604926e-05,
      "loss": 2.168,
      "step": 590
    },
    {
      "epoch": 0.130726074404924,
      "grad_norm": 3.108574628829956,
      "learning_rate": 8.699062976683374e-05,
      "loss": 2.1536,
      "step": 600
    },
    {
      "epoch": 0.13290484231167274,
      "grad_norm": 3.4082131385803223,
      "learning_rate": 8.677271736761822e-05,
      "loss": 2.1875,
      "step": 610
    },
    {
      "epoch": 0.1350836102184215,
      "grad_norm": 1.4820592403411865,
      "learning_rate": 8.65548049684027e-05,
      "loss": 2.304,
      "step": 620
    },
    {
      "epoch": 0.13726237812517023,
      "grad_norm": 1.2334250211715698,
      "learning_rate": 8.633689256918719e-05,
      "loss": 2.0117,
      "step": 630
    },
    {
      "epoch": 0.13944114603191896,
      "grad_norm": 1.8166018724441528,
      "learning_rate": 8.611898016997168e-05,
      "loss": 2.2251,
      "step": 640
    },
    {
      "epoch": 0.14161991393866769,
      "grad_norm": 1.8228261470794678,
      "learning_rate": 8.590106777075616e-05,
      "loss": 2.1497,
      "step": 650
    },
    {
      "epoch": 0.14379868184541642,
      "grad_norm": 1.928531289100647,
      "learning_rate": 8.568315537154065e-05,
      "loss": 2.04,
      "step": 660
    },
    {
      "epoch": 0.14597744975216514,
      "grad_norm": 1.2087217569351196,
      "learning_rate": 8.546524297232513e-05,
      "loss": 1.9882,
      "step": 670
    },
    {
      "epoch": 0.14815621765891387,
      "grad_norm": 1.2050374746322632,
      "learning_rate": 8.524733057310962e-05,
      "loss": 2.0991,
      "step": 680
    },
    {
      "epoch": 0.1503349855656626,
      "grad_norm": 1.188932180404663,
      "learning_rate": 8.502941817389409e-05,
      "loss": 2.1341,
      "step": 690
    },
    {
      "epoch": 0.15251375347241136,
      "grad_norm": 1.5196043252944946,
      "learning_rate": 8.481150577467858e-05,
      "loss": 2.2539,
      "step": 700
    },
    {
      "epoch": 0.1546925213791601,
      "grad_norm": 2.6775732040405273,
      "learning_rate": 8.459359337546307e-05,
      "loss": 2.071,
      "step": 710
    },
    {
      "epoch": 0.15687128928590882,
      "grad_norm": 1.2115193605422974,
      "learning_rate": 8.437568097624755e-05,
      "loss": 2.2097,
      "step": 720
    },
    {
      "epoch": 0.15905005719265755,
      "grad_norm": 1.2957932949066162,
      "learning_rate": 8.415776857703204e-05,
      "loss": 2.3158,
      "step": 730
    },
    {
      "epoch": 0.16122882509940628,
      "grad_norm": 2.7285714149475098,
      "learning_rate": 8.393985617781652e-05,
      "loss": 2.1633,
      "step": 740
    },
    {
      "epoch": 0.163407593006155,
      "grad_norm": 1.3454047441482544,
      "learning_rate": 8.372194377860101e-05,
      "loss": 2.1386,
      "step": 750
    },
    {
      "epoch": 0.16558636091290374,
      "grad_norm": 3.501412868499756,
      "learning_rate": 8.350403137938549e-05,
      "loss": 2.0968,
      "step": 760
    },
    {
      "epoch": 0.1677651288196525,
      "grad_norm": 1.4316409826278687,
      "learning_rate": 8.328611898016998e-05,
      "loss": 2.089,
      "step": 770
    },
    {
      "epoch": 0.16994389672640123,
      "grad_norm": 1.7953709363937378,
      "learning_rate": 8.306820658095445e-05,
      "loss": 2.1704,
      "step": 780
    },
    {
      "epoch": 0.17212266463314996,
      "grad_norm": 1.4698837995529175,
      "learning_rate": 8.285029418173894e-05,
      "loss": 2.1664,
      "step": 790
    },
    {
      "epoch": 0.1743014325398987,
      "grad_norm": 2.008013963699341,
      "learning_rate": 8.263238178252343e-05,
      "loss": 2.1408,
      "step": 800
    },
    {
      "epoch": 0.17648020044664742,
      "grad_norm": 1.0687659978866577,
      "learning_rate": 8.241446938330791e-05,
      "loss": 2.1837,
      "step": 810
    },
    {
      "epoch": 0.17865896835339615,
      "grad_norm": 1.3458054065704346,
      "learning_rate": 8.21965569840924e-05,
      "loss": 2.1378,
      "step": 820
    },
    {
      "epoch": 0.18083773626014488,
      "grad_norm": 1.6542977094650269,
      "learning_rate": 8.197864458487688e-05,
      "loss": 2.1394,
      "step": 830
    },
    {
      "epoch": 0.18301650416689363,
      "grad_norm": 1.2295136451721191,
      "learning_rate": 8.176073218566137e-05,
      "loss": 2.096,
      "step": 840
    },
    {
      "epoch": 0.18519527207364236,
      "grad_norm": 2.8254809379577637,
      "learning_rate": 8.154281978644585e-05,
      "loss": 2.2576,
      "step": 850
    },
    {
      "epoch": 0.1873740399803911,
      "grad_norm": 1.8423445224761963,
      "learning_rate": 8.132490738723034e-05,
      "loss": 2.1451,
      "step": 860
    },
    {
      "epoch": 0.18955280788713982,
      "grad_norm": 2.669198513031006,
      "learning_rate": 8.110699498801482e-05,
      "loss": 2.0619,
      "step": 870
    },
    {
      "epoch": 0.19173157579388855,
      "grad_norm": 1.8644201755523682,
      "learning_rate": 8.08890825887993e-05,
      "loss": 2.3429,
      "step": 880
    },
    {
      "epoch": 0.19391034370063728,
      "grad_norm": 2.241095781326294,
      "learning_rate": 8.06711701895838e-05,
      "loss": 2.0896,
      "step": 890
    },
    {
      "epoch": 0.196089111607386,
      "grad_norm": 0.9314016103744507,
      "learning_rate": 8.045325779036827e-05,
      "loss": 2.1712,
      "step": 900
    },
    {
      "epoch": 0.19826787951413477,
      "grad_norm": 1.461857557296753,
      "learning_rate": 8.023534539115276e-05,
      "loss": 1.91,
      "step": 910
    },
    {
      "epoch": 0.2004466474208835,
      "grad_norm": 0.9794247150421143,
      "learning_rate": 8.001743299193724e-05,
      "loss": 2.2427,
      "step": 920
    },
    {
      "epoch": 0.20262541532763223,
      "grad_norm": 5.005170822143555,
      "learning_rate": 7.979952059272174e-05,
      "loss": 2.1972,
      "step": 930
    },
    {
      "epoch": 0.20480418323438096,
      "grad_norm": 2.3475871086120605,
      "learning_rate": 7.958160819350621e-05,
      "loss": 2.1244,
      "step": 940
    },
    {
      "epoch": 0.2069829511411297,
      "grad_norm": 2.0136983394622803,
      "learning_rate": 7.93636957942907e-05,
      "loss": 2.1571,
      "step": 950
    },
    {
      "epoch": 0.20916171904787842,
      "grad_norm": 1.314723253250122,
      "learning_rate": 7.914578339507518e-05,
      "loss": 1.9476,
      "step": 960
    },
    {
      "epoch": 0.21134048695462715,
      "grad_norm": 3.08613920211792,
      "learning_rate": 7.892787099585966e-05,
      "loss": 2.1123,
      "step": 970
    },
    {
      "epoch": 0.21351925486137588,
      "grad_norm": 1.3171031475067139,
      "learning_rate": 7.870995859664416e-05,
      "loss": 2.1297,
      "step": 980
    },
    {
      "epoch": 0.21569802276812464,
      "grad_norm": 1.9407415390014648,
      "learning_rate": 7.849204619742863e-05,
      "loss": 2.0041,
      "step": 990
    },
    {
      "epoch": 0.21787679067487337,
      "grad_norm": 1.9712063074111938,
      "learning_rate": 7.827413379821313e-05,
      "loss": 2.0464,
      "step": 1000
    },
    {
      "epoch": 0.2200555585816221,
      "grad_norm": 1.7994980812072754,
      "learning_rate": 7.80562213989976e-05,
      "loss": 2.0532,
      "step": 1010
    },
    {
      "epoch": 0.22223432648837083,
      "grad_norm": 2.4882309436798096,
      "learning_rate": 7.78383089997821e-05,
      "loss": 2.1178,
      "step": 1020
    },
    {
      "epoch": 0.22441309439511956,
      "grad_norm": 1.3652235269546509,
      "learning_rate": 7.762039660056658e-05,
      "loss": 2.1851,
      "step": 1030
    },
    {
      "epoch": 0.22659186230186829,
      "grad_norm": 1.1991485357284546,
      "learning_rate": 7.740248420135105e-05,
      "loss": 2.1374,
      "step": 1040
    },
    {
      "epoch": 0.22877063020861702,
      "grad_norm": 1.3797941207885742,
      "learning_rate": 7.718457180213555e-05,
      "loss": 2.1841,
      "step": 1050
    },
    {
      "epoch": 0.23094939811536577,
      "grad_norm": 4.647283554077148,
      "learning_rate": 7.696665940292002e-05,
      "loss": 2.1549,
      "step": 1060
    },
    {
      "epoch": 0.2331281660221145,
      "grad_norm": 1.5415781736373901,
      "learning_rate": 7.674874700370452e-05,
      "loss": 2.1069,
      "step": 1070
    },
    {
      "epoch": 0.23530693392886323,
      "grad_norm": 1.7553777694702148,
      "learning_rate": 7.6530834604489e-05,
      "loss": 2.1207,
      "step": 1080
    },
    {
      "epoch": 0.23748570183561196,
      "grad_norm": 1.827124834060669,
      "learning_rate": 7.631292220527349e-05,
      "loss": 2.0076,
      "step": 1090
    },
    {
      "epoch": 0.2396644697423607,
      "grad_norm": 1.450329303741455,
      "learning_rate": 7.609500980605797e-05,
      "loss": 2.1072,
      "step": 1100
    },
    {
      "epoch": 0.24184323764910942,
      "grad_norm": 2.071873664855957,
      "learning_rate": 7.587709740684246e-05,
      "loss": 2.1391,
      "step": 1110
    },
    {
      "epoch": 0.24402200555585815,
      "grad_norm": 1.6019344329833984,
      "learning_rate": 7.565918500762694e-05,
      "loss": 2.2359,
      "step": 1120
    },
    {
      "epoch": 0.2462007734626069,
      "grad_norm": 1.4962518215179443,
      "learning_rate": 7.544127260841142e-05,
      "loss": 2.2711,
      "step": 1130
    },
    {
      "epoch": 0.24837954136935564,
      "grad_norm": 1.6130564212799072,
      "learning_rate": 7.522336020919591e-05,
      "loss": 2.1148,
      "step": 1140
    },
    {
      "epoch": 0.25055830927610434,
      "grad_norm": 1.374489426612854,
      "learning_rate": 7.500544780998039e-05,
      "loss": 2.0354,
      "step": 1150
    },
    {
      "epoch": 0.2527370771828531,
      "grad_norm": 1.5464601516723633,
      "learning_rate": 7.478753541076488e-05,
      "loss": 1.9345,
      "step": 1160
    },
    {
      "epoch": 0.25491584508960186,
      "grad_norm": 2.918794870376587,
      "learning_rate": 7.456962301154936e-05,
      "loss": 2.1481,
      "step": 1170
    },
    {
      "epoch": 0.25709461299635056,
      "grad_norm": 2.795764446258545,
      "learning_rate": 7.435171061233385e-05,
      "loss": 2.224,
      "step": 1180
    },
    {
      "epoch": 0.2592733809030993,
      "grad_norm": 1.5240556001663208,
      "learning_rate": 7.413379821311833e-05,
      "loss": 1.9776,
      "step": 1190
    },
    {
      "epoch": 0.261452148809848,
      "grad_norm": 1.1977351903915405,
      "learning_rate": 7.391588581390282e-05,
      "loss": 1.9485,
      "step": 1200
    },
    {
      "epoch": 0.2636309167165968,
      "grad_norm": 1.5992646217346191,
      "learning_rate": 7.36979734146873e-05,
      "loss": 2.2625,
      "step": 1210
    },
    {
      "epoch": 0.2658096846233455,
      "grad_norm": 3.056800603866577,
      "learning_rate": 7.348006101547178e-05,
      "loss": 2.0873,
      "step": 1220
    },
    {
      "epoch": 0.26798845253009423,
      "grad_norm": 1.658740520477295,
      "learning_rate": 7.326214861625627e-05,
      "loss": 2.2079,
      "step": 1230
    },
    {
      "epoch": 0.270167220436843,
      "grad_norm": 1.589851975440979,
      "learning_rate": 7.304423621704075e-05,
      "loss": 2.0685,
      "step": 1240
    },
    {
      "epoch": 0.2723459883435917,
      "grad_norm": 1.431745171546936,
      "learning_rate": 7.282632381782524e-05,
      "loss": 2.208,
      "step": 1250
    },
    {
      "epoch": 0.27452475625034045,
      "grad_norm": 2.518301248550415,
      "learning_rate": 7.260841141860972e-05,
      "loss": 2.1483,
      "step": 1260
    },
    {
      "epoch": 0.27670352415708915,
      "grad_norm": 1.179429531097412,
      "learning_rate": 7.239049901939421e-05,
      "loss": 2.0419,
      "step": 1270
    },
    {
      "epoch": 0.2788822920638379,
      "grad_norm": 1.6415735483169556,
      "learning_rate": 7.217258662017869e-05,
      "loss": 2.1816,
      "step": 1280
    },
    {
      "epoch": 0.2810610599705866,
      "grad_norm": 1.1521620750427246,
      "learning_rate": 7.195467422096318e-05,
      "loss": 2.2353,
      "step": 1290
    },
    {
      "epoch": 0.28323982787733537,
      "grad_norm": 2.0819783210754395,
      "learning_rate": 7.173676182174766e-05,
      "loss": 2.1548,
      "step": 1300
    },
    {
      "epoch": 0.28541859578408413,
      "grad_norm": 2.0245535373687744,
      "learning_rate": 7.151884942253214e-05,
      "loss": 2.0288,
      "step": 1310
    },
    {
      "epoch": 0.28759736369083283,
      "grad_norm": 2.368478775024414,
      "learning_rate": 7.130093702331663e-05,
      "loss": 2.0972,
      "step": 1320
    },
    {
      "epoch": 0.2897761315975816,
      "grad_norm": 3.471473217010498,
      "learning_rate": 7.108302462410111e-05,
      "loss": 1.9973,
      "step": 1330
    },
    {
      "epoch": 0.2919548995043303,
      "grad_norm": 1.232163906097412,
      "learning_rate": 7.08651122248856e-05,
      "loss": 2.1112,
      "step": 1340
    },
    {
      "epoch": 0.29413366741107905,
      "grad_norm": 1.3262248039245605,
      "learning_rate": 7.064719982567008e-05,
      "loss": 2.0108,
      "step": 1350
    },
    {
      "epoch": 0.29631243531782775,
      "grad_norm": 3.0231664180755615,
      "learning_rate": 7.042928742645457e-05,
      "loss": 2.1297,
      "step": 1360
    },
    {
      "epoch": 0.2984912032245765,
      "grad_norm": 1.918203592300415,
      "learning_rate": 7.021137502723906e-05,
      "loss": 2.059,
      "step": 1370
    },
    {
      "epoch": 0.3006699711313252,
      "grad_norm": 1.5733668804168701,
      "learning_rate": 6.999346262802354e-05,
      "loss": 2.2269,
      "step": 1380
    },
    {
      "epoch": 0.30284873903807397,
      "grad_norm": 2.293034553527832,
      "learning_rate": 6.977555022880802e-05,
      "loss": 2.0657,
      "step": 1390
    },
    {
      "epoch": 0.3050275069448227,
      "grad_norm": 1.2885907888412476,
      "learning_rate": 6.95576378295925e-05,
      "loss": 2.2144,
      "step": 1400
    },
    {
      "epoch": 0.3072062748515714,
      "grad_norm": 1.3530619144439697,
      "learning_rate": 6.933972543037699e-05,
      "loss": 2.0896,
      "step": 1410
    },
    {
      "epoch": 0.3093850427583202,
      "grad_norm": 2.9077072143554688,
      "learning_rate": 6.912181303116147e-05,
      "loss": 2.2551,
      "step": 1420
    },
    {
      "epoch": 0.3115638106650689,
      "grad_norm": 1.5916748046875,
      "learning_rate": 6.890390063194596e-05,
      "loss": 2.147,
      "step": 1430
    },
    {
      "epoch": 0.31374257857181764,
      "grad_norm": 3.084604263305664,
      "learning_rate": 6.868598823273044e-05,
      "loss": 2.1374,
      "step": 1440
    },
    {
      "epoch": 0.31592134647856634,
      "grad_norm": 1.5414812564849854,
      "learning_rate": 6.846807583351493e-05,
      "loss": 2.0888,
      "step": 1450
    },
    {
      "epoch": 0.3181001143853151,
      "grad_norm": 1.8220460414886475,
      "learning_rate": 6.825016343429942e-05,
      "loss": 2.2268,
      "step": 1460
    },
    {
      "epoch": 0.32027888229206386,
      "grad_norm": 1.40175461769104,
      "learning_rate": 6.80322510350839e-05,
      "loss": 2.1039,
      "step": 1470
    },
    {
      "epoch": 0.32245765019881256,
      "grad_norm": 2.4212613105773926,
      "learning_rate": 6.781433863586838e-05,
      "loss": 2.1423,
      "step": 1480
    },
    {
      "epoch": 0.3246364181055613,
      "grad_norm": 1.7473738193511963,
      "learning_rate": 6.759642623665286e-05,
      "loss": 2.0796,
      "step": 1490
    },
    {
      "epoch": 0.32681518601231,
      "grad_norm": 1.2831602096557617,
      "learning_rate": 6.737851383743735e-05,
      "loss": 2.1776,
      "step": 1500
    },
    {
      "epoch": 0.3289939539190588,
      "grad_norm": 4.40971040725708,
      "learning_rate": 6.716060143822183e-05,
      "loss": 2.2058,
      "step": 1510
    },
    {
      "epoch": 0.3311727218258075,
      "grad_norm": 1.2392328977584839,
      "learning_rate": 6.694268903900632e-05,
      "loss": 2.2161,
      "step": 1520
    },
    {
      "epoch": 0.33335148973255624,
      "grad_norm": 1.0901366472244263,
      "learning_rate": 6.672477663979082e-05,
      "loss": 2.133,
      "step": 1530
    },
    {
      "epoch": 0.335530257639305,
      "grad_norm": 1.8966116905212402,
      "learning_rate": 6.65068642405753e-05,
      "loss": 2.087,
      "step": 1540
    },
    {
      "epoch": 0.3377090255460537,
      "grad_norm": 3.394688606262207,
      "learning_rate": 6.628895184135979e-05,
      "loss": 2.166,
      "step": 1550
    },
    {
      "epoch": 0.33988779345280246,
      "grad_norm": 1.6670737266540527,
      "learning_rate": 6.607103944214425e-05,
      "loss": 2.1019,
      "step": 1560
    },
    {
      "epoch": 0.34206656135955116,
      "grad_norm": 1.4826219081878662,
      "learning_rate": 6.585312704292874e-05,
      "loss": 2.1274,
      "step": 1570
    },
    {
      "epoch": 0.3442453292662999,
      "grad_norm": 1.50246000289917,
      "learning_rate": 6.563521464371322e-05,
      "loss": 2.0005,
      "step": 1580
    },
    {
      "epoch": 0.3464240971730486,
      "grad_norm": 3.0111167430877686,
      "learning_rate": 6.541730224449771e-05,
      "loss": 2.1106,
      "step": 1590
    },
    {
      "epoch": 0.3486028650797974,
      "grad_norm": 1.2677102088928223,
      "learning_rate": 6.51993898452822e-05,
      "loss": 2.0598,
      "step": 1600
    },
    {
      "epoch": 0.35078163298654613,
      "grad_norm": 1.0436275005340576,
      "learning_rate": 6.498147744606668e-05,
      "loss": 2.2186,
      "step": 1610
    },
    {
      "epoch": 0.35296040089329483,
      "grad_norm": 1.3867958784103394,
      "learning_rate": 6.476356504685118e-05,
      "loss": 2.1833,
      "step": 1620
    },
    {
      "epoch": 0.3551391688000436,
      "grad_norm": 3.777977466583252,
      "learning_rate": 6.454565264763566e-05,
      "loss": 2.0125,
      "step": 1630
    },
    {
      "epoch": 0.3573179367067923,
      "grad_norm": 1.0685372352600098,
      "learning_rate": 6.432774024842015e-05,
      "loss": 1.9846,
      "step": 1640
    },
    {
      "epoch": 0.35949670461354105,
      "grad_norm": 1.124735951423645,
      "learning_rate": 6.410982784920461e-05,
      "loss": 2.0472,
      "step": 1650
    },
    {
      "epoch": 0.36167547252028975,
      "grad_norm": 1.2266674041748047,
      "learning_rate": 6.38919154499891e-05,
      "loss": 2.2614,
      "step": 1660
    },
    {
      "epoch": 0.3638542404270385,
      "grad_norm": 1.1464791297912598,
      "learning_rate": 6.367400305077358e-05,
      "loss": 2.0593,
      "step": 1670
    },
    {
      "epoch": 0.36603300833378727,
      "grad_norm": 2.3691089153289795,
      "learning_rate": 6.345609065155808e-05,
      "loss": 2.1338,
      "step": 1680
    },
    {
      "epoch": 0.36821177624053597,
      "grad_norm": 1.7880980968475342,
      "learning_rate": 6.323817825234257e-05,
      "loss": 2.0248,
      "step": 1690
    },
    {
      "epoch": 0.37039054414728473,
      "grad_norm": 1.9202122688293457,
      "learning_rate": 6.302026585312705e-05,
      "loss": 2.0576,
      "step": 1700
    },
    {
      "epoch": 0.37256931205403343,
      "grad_norm": 3.1656439304351807,
      "learning_rate": 6.280235345391154e-05,
      "loss": 2.0506,
      "step": 1710
    },
    {
      "epoch": 0.3747480799607822,
      "grad_norm": 1.759230613708496,
      "learning_rate": 6.258444105469602e-05,
      "loss": 2.2482,
      "step": 1720
    },
    {
      "epoch": 0.3769268478675309,
      "grad_norm": 2.229011297225952,
      "learning_rate": 6.236652865548051e-05,
      "loss": 2.3319,
      "step": 1730
    },
    {
      "epoch": 0.37910561577427965,
      "grad_norm": 3.3038504123687744,
      "learning_rate": 6.214861625626497e-05,
      "loss": 2.0321,
      "step": 1740
    },
    {
      "epoch": 0.3812843836810284,
      "grad_norm": 1.4539706707000732,
      "learning_rate": 6.193070385704947e-05,
      "loss": 2.0938,
      "step": 1750
    },
    {
      "epoch": 0.3834631515877771,
      "grad_norm": 1.3356820344924927,
      "learning_rate": 6.171279145783396e-05,
      "loss": 2.2232,
      "step": 1760
    },
    {
      "epoch": 0.38564191949452586,
      "grad_norm": 1.6181402206420898,
      "learning_rate": 6.149487905861844e-05,
      "loss": 2.1003,
      "step": 1770
    },
    {
      "epoch": 0.38782068740127457,
      "grad_norm": 1.9461253881454468,
      "learning_rate": 6.127696665940293e-05,
      "loss": 2.1192,
      "step": 1780
    },
    {
      "epoch": 0.3899994553080233,
      "grad_norm": 1.1333423852920532,
      "learning_rate": 6.105905426018741e-05,
      "loss": 2.0318,
      "step": 1790
    },
    {
      "epoch": 0.392178223214772,
      "grad_norm": 1.2982378005981445,
      "learning_rate": 6.084114186097189e-05,
      "loss": 2.1153,
      "step": 1800
    },
    {
      "epoch": 0.3943569911215208,
      "grad_norm": 1.343380093574524,
      "learning_rate": 6.0623229461756384e-05,
      "loss": 2.1702,
      "step": 1810
    },
    {
      "epoch": 0.39653575902826954,
      "grad_norm": 1.4141497611999512,
      "learning_rate": 6.0405317062540856e-05,
      "loss": 2.1191,
      "step": 1820
    },
    {
      "epoch": 0.39871452693501824,
      "grad_norm": 1.9709727764129639,
      "learning_rate": 6.018740466332534e-05,
      "loss": 2.1442,
      "step": 1830
    },
    {
      "epoch": 0.400893294841767,
      "grad_norm": 1.440389633178711,
      "learning_rate": 5.996949226410983e-05,
      "loss": 2.1069,
      "step": 1840
    },
    {
      "epoch": 0.4030720627485157,
      "grad_norm": 1.6685501337051392,
      "learning_rate": 5.975157986489431e-05,
      "loss": 2.1447,
      "step": 1850
    },
    {
      "epoch": 0.40525083065526446,
      "grad_norm": 1.150288462638855,
      "learning_rate": 5.95336674656788e-05,
      "loss": 2.1621,
      "step": 1860
    },
    {
      "epoch": 0.40742959856201316,
      "grad_norm": 1.570215106010437,
      "learning_rate": 5.931575506646328e-05,
      "loss": 2.0966,
      "step": 1870
    },
    {
      "epoch": 0.4096083664687619,
      "grad_norm": 1.5499454736709595,
      "learning_rate": 5.909784266724777e-05,
      "loss": 2.2127,
      "step": 1880
    },
    {
      "epoch": 0.4117871343755106,
      "grad_norm": 2.5944254398345947,
      "learning_rate": 5.887993026803226e-05,
      "loss": 2.3134,
      "step": 1890
    },
    {
      "epoch": 0.4139659022822594,
      "grad_norm": 2.108543872833252,
      "learning_rate": 5.8662017868816746e-05,
      "loss": 2.078,
      "step": 1900
    },
    {
      "epoch": 0.41614467018900814,
      "grad_norm": 1.3030444383621216,
      "learning_rate": 5.844410546960122e-05,
      "loss": 2.0469,
      "step": 1910
    },
    {
      "epoch": 0.41832343809575684,
      "grad_norm": 2.354580879211426,
      "learning_rate": 5.82261930703857e-05,
      "loss": 2.1231,
      "step": 1920
    },
    {
      "epoch": 0.4205022060025056,
      "grad_norm": 1.8924431800842285,
      "learning_rate": 5.800828067117019e-05,
      "loss": 2.1936,
      "step": 1930
    },
    {
      "epoch": 0.4226809739092543,
      "grad_norm": 1.6625033617019653,
      "learning_rate": 5.7790368271954674e-05,
      "loss": 2.0898,
      "step": 1940
    },
    {
      "epoch": 0.42485974181600306,
      "grad_norm": 3.1503758430480957,
      "learning_rate": 5.757245587273916e-05,
      "loss": 2.1212,
      "step": 1950
    },
    {
      "epoch": 0.42703850972275176,
      "grad_norm": 1.740299940109253,
      "learning_rate": 5.7354543473523644e-05,
      "loss": 2.1057,
      "step": 1960
    },
    {
      "epoch": 0.4292172776295005,
      "grad_norm": 1.2533472776412964,
      "learning_rate": 5.7136631074308136e-05,
      "loss": 2.1723,
      "step": 1970
    },
    {
      "epoch": 0.4313960455362493,
      "grad_norm": 1.8109385967254639,
      "learning_rate": 5.691871867509262e-05,
      "loss": 2.12,
      "step": 1980
    },
    {
      "epoch": 0.433574813442998,
      "grad_norm": 2.055332660675049,
      "learning_rate": 5.670080627587711e-05,
      "loss": 2.1666,
      "step": 1990
    },
    {
      "epoch": 0.43575358134974673,
      "grad_norm": 1.956063151359558,
      "learning_rate": 5.648289387666158e-05,
      "loss": 2.192,
      "step": 2000
    },
    {
      "epoch": 0.43793234925649543,
      "grad_norm": 1.2058440446853638,
      "learning_rate": 5.6264981477446064e-05,
      "loss": 2.1928,
      "step": 2010
    },
    {
      "epoch": 0.4401111171632442,
      "grad_norm": 1.7220356464385986,
      "learning_rate": 5.604706907823055e-05,
      "loss": 2.0717,
      "step": 2020
    },
    {
      "epoch": 0.4422898850699929,
      "grad_norm": 2.6123228073120117,
      "learning_rate": 5.5829156679015035e-05,
      "loss": 2.1337,
      "step": 2030
    },
    {
      "epoch": 0.44446865297674165,
      "grad_norm": 1.186959147453308,
      "learning_rate": 5.561124427979953e-05,
      "loss": 2.1933,
      "step": 2040
    },
    {
      "epoch": 0.4466474208834904,
      "grad_norm": 6.464845180511475,
      "learning_rate": 5.539333188058401e-05,
      "loss": 2.1563,
      "step": 2050
    },
    {
      "epoch": 0.4488261887902391,
      "grad_norm": 1.617883563041687,
      "learning_rate": 5.51754194813685e-05,
      "loss": 2.1829,
      "step": 2060
    },
    {
      "epoch": 0.45100495669698787,
      "grad_norm": 1.8449441194534302,
      "learning_rate": 5.495750708215298e-05,
      "loss": 2.2452,
      "step": 2070
    },
    {
      "epoch": 0.45318372460373657,
      "grad_norm": 1.616424560546875,
      "learning_rate": 5.473959468293747e-05,
      "loss": 2.1457,
      "step": 2080
    },
    {
      "epoch": 0.45536249251048533,
      "grad_norm": 1.8934489488601685,
      "learning_rate": 5.452168228372194e-05,
      "loss": 2.1507,
      "step": 2090
    },
    {
      "epoch": 0.45754126041723403,
      "grad_norm": 1.4579435586929321,
      "learning_rate": 5.432556112442798e-05,
      "loss": 2.2182,
      "step": 2100
    },
    {
      "epoch": 0.4597200283239828,
      "grad_norm": 1.3702163696289062,
      "learning_rate": 5.410764872521247e-05,
      "loss": 2.1272,
      "step": 2110
    },
    {
      "epoch": 0.46189879623073155,
      "grad_norm": 1.4311197996139526,
      "learning_rate": 5.388973632599695e-05,
      "loss": 2.0321,
      "step": 2120
    },
    {
      "epoch": 0.46407756413748025,
      "grad_norm": 1.215116024017334,
      "learning_rate": 5.367182392678144e-05,
      "loss": 2.1649,
      "step": 2130
    },
    {
      "epoch": 0.466256332044229,
      "grad_norm": 1.558540940284729,
      "learning_rate": 5.345391152756592e-05,
      "loss": 2.3172,
      "step": 2140
    },
    {
      "epoch": 0.4684350999509777,
      "grad_norm": 2.02002215385437,
      "learning_rate": 5.323599912835041e-05,
      "loss": 1.9345,
      "step": 2150
    },
    {
      "epoch": 0.47061386785772646,
      "grad_norm": 1.263930082321167,
      "learning_rate": 5.301808672913489e-05,
      "loss": 2.1353,
      "step": 2160
    },
    {
      "epoch": 0.47279263576447517,
      "grad_norm": 1.2910947799682617,
      "learning_rate": 5.280017432991937e-05,
      "loss": 2.1103,
      "step": 2170
    },
    {
      "epoch": 0.4749714036712239,
      "grad_norm": 1.6752939224243164,
      "learning_rate": 5.258226193070386e-05,
      "loss": 2.1134,
      "step": 2180
    },
    {
      "epoch": 0.4771501715779727,
      "grad_norm": 1.2475554943084717,
      "learning_rate": 5.236434953148834e-05,
      "loss": 2.0016,
      "step": 2190
    },
    {
      "epoch": 0.4793289394847214,
      "grad_norm": 6.59671688079834,
      "learning_rate": 5.214643713227283e-05,
      "loss": 2.2053,
      "step": 2200
    },
    {
      "epoch": 0.48150770739147014,
      "grad_norm": 1.6619439125061035,
      "learning_rate": 5.1928524733057314e-05,
      "loss": 2.1476,
      "step": 2210
    },
    {
      "epoch": 0.48368647529821884,
      "grad_norm": 2.4493346214294434,
      "learning_rate": 5.17106123338418e-05,
      "loss": 2.3037,
      "step": 2220
    },
    {
      "epoch": 0.4858652432049676,
      "grad_norm": 1.739459753036499,
      "learning_rate": 5.1492699934626284e-05,
      "loss": 2.1812,
      "step": 2230
    },
    {
      "epoch": 0.4880440111117163,
      "grad_norm": 2.940246343612671,
      "learning_rate": 5.127478753541076e-05,
      "loss": 2.0727,
      "step": 2240
    },
    {
      "epoch": 0.49022277901846506,
      "grad_norm": 1.1492838859558105,
      "learning_rate": 5.105687513619525e-05,
      "loss": 2.0899,
      "step": 2250
    },
    {
      "epoch": 0.4924015469252138,
      "grad_norm": 1.651868224143982,
      "learning_rate": 5.0838962736979733e-05,
      "loss": 2.0394,
      "step": 2260
    },
    {
      "epoch": 0.4945803148319625,
      "grad_norm": 1.3784559965133667,
      "learning_rate": 5.062105033776422e-05,
      "loss": 2.0387,
      "step": 2270
    },
    {
      "epoch": 0.4967590827387113,
      "grad_norm": 1.2165162563323975,
      "learning_rate": 5.0403137938548704e-05,
      "loss": 2.2141,
      "step": 2280
    },
    {
      "epoch": 0.49893785064546,
      "grad_norm": 1.6408780813217163,
      "learning_rate": 5.018522553933319e-05,
      "loss": 2.0158,
      "step": 2290
    },
    {
      "epoch": 0.5011166185522087,
      "grad_norm": 1.1963627338409424,
      "learning_rate": 4.9967313140117675e-05,
      "loss": 2.0942,
      "step": 2300
    },
    {
      "epoch": 0.5032953864589574,
      "grad_norm": 1.2163190841674805,
      "learning_rate": 4.974940074090216e-05,
      "loss": 2.0289,
      "step": 2310
    },
    {
      "epoch": 0.5054741543657062,
      "grad_norm": 1.9486987590789795,
      "learning_rate": 4.9531488341686646e-05,
      "loss": 2.0953,
      "step": 2320
    },
    {
      "epoch": 0.507652922272455,
      "grad_norm": 1.288230538368225,
      "learning_rate": 4.931357594247113e-05,
      "loss": 2.1542,
      "step": 2330
    },
    {
      "epoch": 0.5098316901792037,
      "grad_norm": 2.440814256668091,
      "learning_rate": 4.9095663543255616e-05,
      "loss": 2.1119,
      "step": 2340
    },
    {
      "epoch": 0.5120104580859524,
      "grad_norm": 1.3533514738082886,
      "learning_rate": 4.8877751144040095e-05,
      "loss": 2.2727,
      "step": 2350
    },
    {
      "epoch": 0.5141892259927011,
      "grad_norm": 2.65734601020813,
      "learning_rate": 4.865983874482458e-05,
      "loss": 2.1002,
      "step": 2360
    },
    {
      "epoch": 0.5163679938994499,
      "grad_norm": 1.3849306106567383,
      "learning_rate": 4.8441926345609065e-05,
      "loss": 2.0892,
      "step": 2370
    },
    {
      "epoch": 0.5185467618061986,
      "grad_norm": 1.9693055152893066,
      "learning_rate": 4.822401394639355e-05,
      "loss": 2.0234,
      "step": 2380
    },
    {
      "epoch": 0.5207255297129473,
      "grad_norm": 1.8010122776031494,
      "learning_rate": 4.8006101547178036e-05,
      "loss": 2.0729,
      "step": 2390
    },
    {
      "epoch": 0.522904297619696,
      "grad_norm": 2.7079055309295654,
      "learning_rate": 4.778818914796252e-05,
      "loss": 2.0933,
      "step": 2400
    },
    {
      "epoch": 0.5250830655264448,
      "grad_norm": 1.312022089958191,
      "learning_rate": 4.757027674874701e-05,
      "loss": 2.0762,
      "step": 2410
    },
    {
      "epoch": 0.5272618334331935,
      "grad_norm": 2.0365095138549805,
      "learning_rate": 4.735236434953149e-05,
      "loss": 2.326,
      "step": 2420
    },
    {
      "epoch": 0.5294406013399423,
      "grad_norm": 1.0161195993423462,
      "learning_rate": 4.713445195031598e-05,
      "loss": 2.1581,
      "step": 2430
    },
    {
      "epoch": 0.531619369246691,
      "grad_norm": 1.2298738956451416,
      "learning_rate": 4.6916539551100456e-05,
      "loss": 2.0487,
      "step": 2440
    },
    {
      "epoch": 0.5337981371534397,
      "grad_norm": 1.2411842346191406,
      "learning_rate": 4.669862715188494e-05,
      "loss": 2.1278,
      "step": 2450
    },
    {
      "epoch": 0.5359769050601885,
      "grad_norm": 1.5631117820739746,
      "learning_rate": 4.648071475266943e-05,
      "loss": 2.2235,
      "step": 2460
    },
    {
      "epoch": 0.5381556729669372,
      "grad_norm": 1.935755968093872,
      "learning_rate": 4.626280235345392e-05,
      "loss": 2.2284,
      "step": 2470
    },
    {
      "epoch": 0.540334440873686,
      "grad_norm": 4.269099235534668,
      "learning_rate": 4.60448899542384e-05,
      "loss": 2.1578,
      "step": 2480
    },
    {
      "epoch": 0.5425132087804346,
      "grad_norm": 1.0953139066696167,
      "learning_rate": 4.582697755502288e-05,
      "loss": 2.2443,
      "step": 2490
    },
    {
      "epoch": 0.5446919766871834,
      "grad_norm": 1.1949567794799805,
      "learning_rate": 4.560906515580737e-05,
      "loss": 2.1463,
      "step": 2500
    },
    {
      "epoch": 0.5468707445939321,
      "grad_norm": 2.4541807174682617,
      "learning_rate": 4.5391152756591853e-05,
      "loss": 2.0507,
      "step": 2510
    },
    {
      "epoch": 0.5490495125006809,
      "grad_norm": 2.158221483230591,
      "learning_rate": 4.517324035737634e-05,
      "loss": 2.1051,
      "step": 2520
    },
    {
      "epoch": 0.5512282804074295,
      "grad_norm": 1.72701096534729,
      "learning_rate": 4.495532795816082e-05,
      "loss": 2.0343,
      "step": 2530
    },
    {
      "epoch": 0.5534070483141783,
      "grad_norm": 1.0556137561798096,
      "learning_rate": 4.47374155589453e-05,
      "loss": 2.0157,
      "step": 2540
    },
    {
      "epoch": 0.5555858162209271,
      "grad_norm": 1.60857093334198,
      "learning_rate": 4.4519503159729795e-05,
      "loss": 2.1164,
      "step": 2550
    },
    {
      "epoch": 0.5577645841276758,
      "grad_norm": 1.2867296934127808,
      "learning_rate": 4.430159076051428e-05,
      "loss": 2.1146,
      "step": 2560
    },
    {
      "epoch": 0.5599433520344246,
      "grad_norm": 1.5366047620773315,
      "learning_rate": 4.408367836129876e-05,
      "loss": 2.0021,
      "step": 2570
    },
    {
      "epoch": 0.5621221199411732,
      "grad_norm": 5.229671001434326,
      "learning_rate": 4.3865765962083244e-05,
      "loss": 2.1782,
      "step": 2580
    },
    {
      "epoch": 0.564300887847922,
      "grad_norm": 1.4055085182189941,
      "learning_rate": 4.364785356286773e-05,
      "loss": 2.0375,
      "step": 2590
    },
    {
      "epoch": 0.5664796557546707,
      "grad_norm": 1.501491904258728,
      "learning_rate": 4.3429941163652215e-05,
      "loss": 1.9744,
      "step": 2600
    },
    {
      "epoch": 0.5686584236614195,
      "grad_norm": 1.0603523254394531,
      "learning_rate": 4.321202876443669e-05,
      "loss": 2.0831,
      "step": 2610
    },
    {
      "epoch": 0.5708371915681683,
      "grad_norm": 1.1156857013702393,
      "learning_rate": 4.2994116365221185e-05,
      "loss": 1.9037,
      "step": 2620
    },
    {
      "epoch": 0.5730159594749169,
      "grad_norm": 1.9521690607070923,
      "learning_rate": 4.277620396600567e-05,
      "loss": 2.1293,
      "step": 2630
    },
    {
      "epoch": 0.5751947273816657,
      "grad_norm": 2.399282217025757,
      "learning_rate": 4.2558291566790156e-05,
      "loss": 2.1314,
      "step": 2640
    },
    {
      "epoch": 0.5773734952884144,
      "grad_norm": 1.8964704275131226,
      "learning_rate": 4.234037916757464e-05,
      "loss": 2.0916,
      "step": 2650
    },
    {
      "epoch": 0.5795522631951632,
      "grad_norm": 1.5330677032470703,
      "learning_rate": 4.212246676835912e-05,
      "loss": 2.0798,
      "step": 2660
    },
    {
      "epoch": 0.5817310311019118,
      "grad_norm": 1.5876975059509277,
      "learning_rate": 4.1904554369143605e-05,
      "loss": 2.136,
      "step": 2670
    },
    {
      "epoch": 0.5839097990086606,
      "grad_norm": 1.4950181245803833,
      "learning_rate": 4.168664196992809e-05,
      "loss": 2.1246,
      "step": 2680
    },
    {
      "epoch": 0.5860885669154093,
      "grad_norm": 1.92316734790802,
      "learning_rate": 4.1468729570712576e-05,
      "loss": 2.1413,
      "step": 2690
    },
    {
      "epoch": 0.5882673348221581,
      "grad_norm": 0.8641077876091003,
      "learning_rate": 4.125081717149706e-05,
      "loss": 2.0187,
      "step": 2700
    },
    {
      "epoch": 0.5904461027289069,
      "grad_norm": 1.5245740413665771,
      "learning_rate": 4.103290477228155e-05,
      "loss": 1.9674,
      "step": 2710
    },
    {
      "epoch": 0.5926248706356555,
      "grad_norm": 2.0362913608551025,
      "learning_rate": 4.081499237306603e-05,
      "loss": 1.9845,
      "step": 2720
    },
    {
      "epoch": 0.5948036385424043,
      "grad_norm": 1.5472052097320557,
      "learning_rate": 4.059707997385052e-05,
      "loss": 2.0856,
      "step": 2730
    },
    {
      "epoch": 0.596982406449153,
      "grad_norm": 3.8943772315979004,
      "learning_rate": 4.0379167574634996e-05,
      "loss": 2.2481,
      "step": 2740
    },
    {
      "epoch": 0.5991611743559018,
      "grad_norm": 2.7380154132843018,
      "learning_rate": 4.016125517541948e-05,
      "loss": 2.1978,
      "step": 2750
    },
    {
      "epoch": 0.6013399422626504,
      "grad_norm": 2.2011449337005615,
      "learning_rate": 3.994334277620397e-05,
      "loss": 2.1027,
      "step": 2760
    },
    {
      "epoch": 0.6035187101693992,
      "grad_norm": 1.3468533754348755,
      "learning_rate": 3.972543037698845e-05,
      "loss": 2.0927,
      "step": 2770
    },
    {
      "epoch": 0.6056974780761479,
      "grad_norm": 2.1983842849731445,
      "learning_rate": 3.950751797777294e-05,
      "loss": 1.9877,
      "step": 2780
    },
    {
      "epoch": 0.6078762459828967,
      "grad_norm": 1.7703871726989746,
      "learning_rate": 3.928960557855742e-05,
      "loss": 2.0544,
      "step": 2790
    },
    {
      "epoch": 0.6100550138896454,
      "grad_norm": 1.2156082391738892,
      "learning_rate": 3.907169317934191e-05,
      "loss": 2.1442,
      "step": 2800
    },
    {
      "epoch": 0.6122337817963941,
      "grad_norm": 1.5355595350265503,
      "learning_rate": 3.885378078012639e-05,
      "loss": 2.1226,
      "step": 2810
    },
    {
      "epoch": 0.6144125497031429,
      "grad_norm": 1.766916275024414,
      "learning_rate": 3.863586838091088e-05,
      "loss": 2.0163,
      "step": 2820
    },
    {
      "epoch": 0.6165913176098916,
      "grad_norm": 2.213690757751465,
      "learning_rate": 3.841795598169536e-05,
      "loss": 2.1415,
      "step": 2830
    },
    {
      "epoch": 0.6187700855166404,
      "grad_norm": 2.411400079727173,
      "learning_rate": 3.820004358247984e-05,
      "loss": 2.145,
      "step": 2840
    },
    {
      "epoch": 0.6209488534233891,
      "grad_norm": 1.3468434810638428,
      "learning_rate": 3.798213118326433e-05,
      "loss": 2.139,
      "step": 2850
    },
    {
      "epoch": 0.6231276213301378,
      "grad_norm": 1.392524242401123,
      "learning_rate": 3.776421878404881e-05,
      "loss": 2.1139,
      "step": 2860
    },
    {
      "epoch": 0.6253063892368865,
      "grad_norm": 1.6033743619918823,
      "learning_rate": 3.75463063848333e-05,
      "loss": 2.0473,
      "step": 2870
    },
    {
      "epoch": 0.6274851571436353,
      "grad_norm": 1.6832904815673828,
      "learning_rate": 3.7328393985617784e-05,
      "loss": 2.0829,
      "step": 2880
    },
    {
      "epoch": 0.629663925050384,
      "grad_norm": 1.533509373664856,
      "learning_rate": 3.711048158640227e-05,
      "loss": 2.1259,
      "step": 2890
    },
    {
      "epoch": 0.6318426929571327,
      "grad_norm": 1.8410590887069702,
      "learning_rate": 3.6892569187186755e-05,
      "loss": 2.2675,
      "step": 2900
    },
    {
      "epoch": 0.6340214608638814,
      "grad_norm": 1.1401859521865845,
      "learning_rate": 3.667465678797124e-05,
      "loss": 2.1104,
      "step": 2910
    },
    {
      "epoch": 0.6362002287706302,
      "grad_norm": 5.244893550872803,
      "learning_rate": 3.645674438875572e-05,
      "loss": 1.9094,
      "step": 2920
    },
    {
      "epoch": 0.638378996677379,
      "grad_norm": 1.4222595691680908,
      "learning_rate": 3.6238831989540204e-05,
      "loss": 2.0543,
      "step": 2930
    },
    {
      "epoch": 0.6405577645841277,
      "grad_norm": 1.9422094821929932,
      "learning_rate": 3.602091959032469e-05,
      "loss": 1.9467,
      "step": 2940
    },
    {
      "epoch": 0.6427365324908764,
      "grad_norm": 1.6086909770965576,
      "learning_rate": 3.580300719110918e-05,
      "loss": 2.1627,
      "step": 2950
    },
    {
      "epoch": 0.6449153003976251,
      "grad_norm": 2.2182199954986572,
      "learning_rate": 3.558509479189366e-05,
      "loss": 2.1101,
      "step": 2960
    },
    {
      "epoch": 0.6470940683043739,
      "grad_norm": 2.231292963027954,
      "learning_rate": 3.5367182392678145e-05,
      "loss": 2.2097,
      "step": 2970
    },
    {
      "epoch": 0.6492728362111226,
      "grad_norm": 1.4285393953323364,
      "learning_rate": 3.514926999346263e-05,
      "loss": 2.1561,
      "step": 2980
    },
    {
      "epoch": 0.6514516041178714,
      "grad_norm": 2.0011556148529053,
      "learning_rate": 3.4931357594247116e-05,
      "loss": 1.897,
      "step": 2990
    },
    {
      "epoch": 0.65363037202462,
      "grad_norm": 1.2439022064208984,
      "learning_rate": 3.4713445195031594e-05,
      "loss": 1.9827,
      "step": 3000
    },
    {
      "epoch": 0.6558091399313688,
      "grad_norm": 1.355210781097412,
      "learning_rate": 3.449553279581608e-05,
      "loss": 2.0867,
      "step": 3010
    },
    {
      "epoch": 0.6579879078381176,
      "grad_norm": 1.4571797847747803,
      "learning_rate": 3.4277620396600565e-05,
      "loss": 2.0909,
      "step": 3020
    },
    {
      "epoch": 0.6601666757448663,
      "grad_norm": 1.6192697286605835,
      "learning_rate": 3.405970799738506e-05,
      "loss": 2.1356,
      "step": 3030
    },
    {
      "epoch": 0.662345443651615,
      "grad_norm": 1.7204548120498657,
      "learning_rate": 3.384179559816954e-05,
      "loss": 2.2215,
      "step": 3040
    },
    {
      "epoch": 0.6645242115583637,
      "grad_norm": 1.6851446628570557,
      "learning_rate": 3.362388319895402e-05,
      "loss": 2.1241,
      "step": 3050
    },
    {
      "epoch": 0.6667029794651125,
      "grad_norm": 1.0659877061843872,
      "learning_rate": 3.3405970799738506e-05,
      "loss": 2.0437,
      "step": 3060
    },
    {
      "epoch": 0.6688817473718612,
      "grad_norm": 1.8674976825714111,
      "learning_rate": 3.318805840052299e-05,
      "loss": 2.1431,
      "step": 3070
    },
    {
      "epoch": 0.67106051527861,
      "grad_norm": 1.2282829284667969,
      "learning_rate": 3.297014600130748e-05,
      "loss": 2.0694,
      "step": 3080
    },
    {
      "epoch": 0.6732392831853586,
      "grad_norm": 1.4033793210983276,
      "learning_rate": 3.2752233602091956e-05,
      "loss": 2.1575,
      "step": 3090
    },
    {
      "epoch": 0.6754180510921074,
      "grad_norm": 1.5624306201934814,
      "learning_rate": 3.253432120287644e-05,
      "loss": 2.162,
      "step": 3100
    },
    {
      "epoch": 0.6775968189988562,
      "grad_norm": 1.5295723676681519,
      "learning_rate": 3.231640880366093e-05,
      "loss": 2.0071,
      "step": 3110
    },
    {
      "epoch": 0.6797755869056049,
      "grad_norm": 2.195462465286255,
      "learning_rate": 3.209849640444542e-05,
      "loss": 2.1665,
      "step": 3120
    },
    {
      "epoch": 0.6819543548123537,
      "grad_norm": 1.469773769378662,
      "learning_rate": 3.18805840052299e-05,
      "loss": 2.0777,
      "step": 3130
    },
    {
      "epoch": 0.6841331227191023,
      "grad_norm": 1.7378865480422974,
      "learning_rate": 3.166267160601438e-05,
      "loss": 2.3033,
      "step": 3140
    },
    {
      "epoch": 0.6863118906258511,
      "grad_norm": 1.7069469690322876,
      "learning_rate": 3.144475920679887e-05,
      "loss": 2.1195,
      "step": 3150
    },
    {
      "epoch": 0.6884906585325998,
      "grad_norm": 1.2294970750808716,
      "learning_rate": 3.122684680758335e-05,
      "loss": 2.0577,
      "step": 3160
    },
    {
      "epoch": 0.6906694264393486,
      "grad_norm": 1.269843339920044,
      "learning_rate": 3.100893440836784e-05,
      "loss": 2.2956,
      "step": 3170
    },
    {
      "epoch": 0.6928481943460972,
      "grad_norm": 1.610390305519104,
      "learning_rate": 3.0791022009152324e-05,
      "loss": 2.0183,
      "step": 3180
    },
    {
      "epoch": 0.695026962252846,
      "grad_norm": 1.3206218481063843,
      "learning_rate": 3.057310960993681e-05,
      "loss": 2.1303,
      "step": 3190
    },
    {
      "epoch": 0.6972057301595947,
      "grad_norm": 1.3037128448486328,
      "learning_rate": 3.035519721072129e-05,
      "loss": 2.0539,
      "step": 3200
    },
    {
      "epoch": 0.6993844980663435,
      "grad_norm": 1.165723443031311,
      "learning_rate": 3.013728481150578e-05,
      "loss": 2.1692,
      "step": 3210
    },
    {
      "epoch": 0.7015632659730923,
      "grad_norm": 2.599175453186035,
      "learning_rate": 2.991937241229026e-05,
      "loss": 2.1944,
      "step": 3220
    },
    {
      "epoch": 0.7037420338798409,
      "grad_norm": 3.216352701187134,
      "learning_rate": 2.9701460013074744e-05,
      "loss": 2.0884,
      "step": 3230
    },
    {
      "epoch": 0.7059208017865897,
      "grad_norm": 1.632051706314087,
      "learning_rate": 2.948354761385923e-05,
      "loss": 2.1426,
      "step": 3240
    },
    {
      "epoch": 0.7080995696933384,
      "grad_norm": 2.962101459503174,
      "learning_rate": 2.9265635214643718e-05,
      "loss": 2.2611,
      "step": 3250
    },
    {
      "epoch": 0.7102783376000872,
      "grad_norm": 1.854318618774414,
      "learning_rate": 2.9047722815428196e-05,
      "loss": 2.0704,
      "step": 3260
    },
    {
      "epoch": 0.7124571055068358,
      "grad_norm": 1.2662599086761475,
      "learning_rate": 2.882981041621268e-05,
      "loss": 2.0041,
      "step": 3270
    },
    {
      "epoch": 0.7146358734135846,
      "grad_norm": 1.4289131164550781,
      "learning_rate": 2.8611898016997167e-05,
      "loss": 1.9834,
      "step": 3280
    },
    {
      "epoch": 0.7168146413203333,
      "grad_norm": 1.232029914855957,
      "learning_rate": 2.8393985617781656e-05,
      "loss": 2.0578,
      "step": 3290
    },
    {
      "epoch": 0.7189934092270821,
      "grad_norm": 1.3585453033447266,
      "learning_rate": 2.817607321856614e-05,
      "loss": 2.1594,
      "step": 3300
    },
    {
      "epoch": 0.7211721771338309,
      "grad_norm": 1.743682861328125,
      "learning_rate": 2.795816081935062e-05,
      "loss": 2.1277,
      "step": 3310
    },
    {
      "epoch": 0.7233509450405795,
      "grad_norm": 2.3839640617370605,
      "learning_rate": 2.7740248420135105e-05,
      "loss": 2.15,
      "step": 3320
    },
    {
      "epoch": 0.7255297129473283,
      "grad_norm": 1.7039828300476074,
      "learning_rate": 2.7522336020919594e-05,
      "loss": 2.058,
      "step": 3330
    },
    {
      "epoch": 0.727708480854077,
      "grad_norm": 1.0955110788345337,
      "learning_rate": 2.730442362170408e-05,
      "loss": 2.152,
      "step": 3340
    },
    {
      "epoch": 0.7298872487608258,
      "grad_norm": 1.3085483312606812,
      "learning_rate": 2.7086511222488558e-05,
      "loss": 2.0934,
      "step": 3350
    },
    {
      "epoch": 0.7320660166675745,
      "grad_norm": 1.3959980010986328,
      "learning_rate": 2.6868598823273043e-05,
      "loss": 2.1188,
      "step": 3360
    },
    {
      "epoch": 0.7342447845743232,
      "grad_norm": 1.3981702327728271,
      "learning_rate": 2.665068642405753e-05,
      "loss": 2.1433,
      "step": 3370
    },
    {
      "epoch": 0.7364235524810719,
      "grad_norm": 3.4005961418151855,
      "learning_rate": 2.6432774024842017e-05,
      "loss": 2.1494,
      "step": 3380
    },
    {
      "epoch": 0.7386023203878207,
      "grad_norm": 1.915521502494812,
      "learning_rate": 2.6214861625626496e-05,
      "loss": 2.0236,
      "step": 3390
    },
    {
      "epoch": 0.7407810882945695,
      "grad_norm": 1.3361923694610596,
      "learning_rate": 2.599694922641098e-05,
      "loss": 2.1103,
      "step": 3400
    },
    {
      "epoch": 0.7429598562013181,
      "grad_norm": 3.0288782119750977,
      "learning_rate": 2.577903682719547e-05,
      "loss": 2.1773,
      "step": 3410
    },
    {
      "epoch": 0.7451386241080669,
      "grad_norm": 2.0369763374328613,
      "learning_rate": 2.5561124427979955e-05,
      "loss": 2.1005,
      "step": 3420
    },
    {
      "epoch": 0.7473173920148156,
      "grad_norm": 1.2137559652328491,
      "learning_rate": 2.534321202876444e-05,
      "loss": 2.0579,
      "step": 3430
    },
    {
      "epoch": 0.7494961599215644,
      "grad_norm": 1.075742483139038,
      "learning_rate": 2.5125299629548922e-05,
      "loss": 2.0825,
      "step": 3440
    },
    {
      "epoch": 0.7516749278283131,
      "grad_norm": 1.1188814640045166,
      "learning_rate": 2.4907387230333408e-05,
      "loss": 2.0284,
      "step": 3450
    },
    {
      "epoch": 0.7538536957350618,
      "grad_norm": 1.9443697929382324,
      "learning_rate": 2.4689474831117893e-05,
      "loss": 2.1522,
      "step": 3460
    },
    {
      "epoch": 0.7560324636418105,
      "grad_norm": 1.2775338888168335,
      "learning_rate": 2.4471562431902375e-05,
      "loss": 2.0256,
      "step": 3470
    },
    {
      "epoch": 0.7582112315485593,
      "grad_norm": 1.438859462738037,
      "learning_rate": 2.425365003268686e-05,
      "loss": 2.0264,
      "step": 3480
    },
    {
      "epoch": 0.760389999455308,
      "grad_norm": 2.6417336463928223,
      "learning_rate": 2.4035737633471346e-05,
      "loss": 2.2387,
      "step": 3490
    },
    {
      "epoch": 0.7625687673620568,
      "grad_norm": 3.011247158050537,
      "learning_rate": 2.381782523425583e-05,
      "loss": 2.1524,
      "step": 3500
    },
    {
      "epoch": 0.7647475352688055,
      "grad_norm": 1.1962862014770508,
      "learning_rate": 2.3599912835040313e-05,
      "loss": 1.9798,
      "step": 3510
    },
    {
      "epoch": 0.7669263031755542,
      "grad_norm": 1.3800209760665894,
      "learning_rate": 2.3382000435824798e-05,
      "loss": 2.1458,
      "step": 3520
    },
    {
      "epoch": 0.769105071082303,
      "grad_norm": 2.206634283065796,
      "learning_rate": 2.3164088036609287e-05,
      "loss": 1.9622,
      "step": 3530
    },
    {
      "epoch": 0.7712838389890517,
      "grad_norm": 1.4036564826965332,
      "learning_rate": 2.294617563739377e-05,
      "loss": 2.0912,
      "step": 3540
    },
    {
      "epoch": 0.7734626068958004,
      "grad_norm": 1.5768858194351196,
      "learning_rate": 2.2728263238178254e-05,
      "loss": 1.9955,
      "step": 3550
    },
    {
      "epoch": 0.7756413748025491,
      "grad_norm": 2.228837728500366,
      "learning_rate": 2.2510350838962736e-05,
      "loss": 2.0518,
      "step": 3560
    },
    {
      "epoch": 0.7778201427092979,
      "grad_norm": 1.39779794216156,
      "learning_rate": 2.2292438439747225e-05,
      "loss": 2.1587,
      "step": 3570
    },
    {
      "epoch": 0.7799989106160466,
      "grad_norm": 1.2571197748184204,
      "learning_rate": 2.2074526040531707e-05,
      "loss": 2.082,
      "step": 3580
    },
    {
      "epoch": 0.7821776785227954,
      "grad_norm": 1.2344741821289062,
      "learning_rate": 2.1856613641316192e-05,
      "loss": 2.2209,
      "step": 3590
    },
    {
      "epoch": 0.784356446429544,
      "grad_norm": 1.1992082595825195,
      "learning_rate": 2.1638701242100674e-05,
      "loss": 2.1775,
      "step": 3600
    },
    {
      "epoch": 0.7865352143362928,
      "grad_norm": 2.1162216663360596,
      "learning_rate": 2.1420788842885163e-05,
      "loss": 2.1264,
      "step": 3610
    },
    {
      "epoch": 0.7887139822430416,
      "grad_norm": 2.2894999980926514,
      "learning_rate": 2.1202876443669645e-05,
      "loss": 2.2086,
      "step": 3620
    },
    {
      "epoch": 0.7908927501497903,
      "grad_norm": 4.382574558258057,
      "learning_rate": 2.098496404445413e-05,
      "loss": 2.037,
      "step": 3630
    },
    {
      "epoch": 0.7930715180565391,
      "grad_norm": 1.8182225227355957,
      "learning_rate": 2.0767051645238612e-05,
      "loss": 2.1423,
      "step": 3640
    },
    {
      "epoch": 0.7952502859632877,
      "grad_norm": 1.8486084938049316,
      "learning_rate": 2.05491392460231e-05,
      "loss": 2.1879,
      "step": 3650
    },
    {
      "epoch": 0.7974290538700365,
      "grad_norm": 1.5780667066574097,
      "learning_rate": 2.0331226846807586e-05,
      "loss": 2.1047,
      "step": 3660
    },
    {
      "epoch": 0.7996078217767852,
      "grad_norm": 1.2478430271148682,
      "learning_rate": 2.0113314447592068e-05,
      "loss": 2.2616,
      "step": 3670
    },
    {
      "epoch": 0.801786589683534,
      "grad_norm": 1.9793492555618286,
      "learning_rate": 1.9895402048376554e-05,
      "loss": 2.2388,
      "step": 3680
    },
    {
      "epoch": 0.8039653575902826,
      "grad_norm": 1.3186577558517456,
      "learning_rate": 1.967748964916104e-05,
      "loss": 2.0099,
      "step": 3690
    },
    {
      "epoch": 0.8061441254970314,
      "grad_norm": 1.6326981782913208,
      "learning_rate": 1.9459577249945524e-05,
      "loss": 2.1556,
      "step": 3700
    },
    {
      "epoch": 0.8083228934037802,
      "grad_norm": 1.0793882608413696,
      "learning_rate": 1.9241664850730006e-05,
      "loss": 2.0584,
      "step": 3710
    },
    {
      "epoch": 0.8105016613105289,
      "grad_norm": 1.3794333934783936,
      "learning_rate": 1.902375245151449e-05,
      "loss": 2.0528,
      "step": 3720
    },
    {
      "epoch": 0.8126804292172777,
      "grad_norm": 1.3026695251464844,
      "learning_rate": 1.8805840052298977e-05,
      "loss": 2.1224,
      "step": 3730
    },
    {
      "epoch": 0.8148591971240263,
      "grad_norm": 1.8789571523666382,
      "learning_rate": 1.8587927653083462e-05,
      "loss": 2.2982,
      "step": 3740
    },
    {
      "epoch": 0.8170379650307751,
      "grad_norm": 1.3939263820648193,
      "learning_rate": 1.8370015253867944e-05,
      "loss": 2.1174,
      "step": 3750
    },
    {
      "epoch": 0.8192167329375238,
      "grad_norm": 1.347856044769287,
      "learning_rate": 1.815210285465243e-05,
      "loss": 2.1267,
      "step": 3760
    },
    {
      "epoch": 0.8213955008442726,
      "grad_norm": 1.291134238243103,
      "learning_rate": 1.7934190455436915e-05,
      "loss": 2.0325,
      "step": 3770
    },
    {
      "epoch": 0.8235742687510212,
      "grad_norm": 1.7798436880111694,
      "learning_rate": 1.77162780562214e-05,
      "loss": 1.9903,
      "step": 3780
    },
    {
      "epoch": 0.82575303665777,
      "grad_norm": 1.3618494272232056,
      "learning_rate": 1.7498365657005885e-05,
      "loss": 2.0435,
      "step": 3790
    },
    {
      "epoch": 0.8279318045645188,
      "grad_norm": 1.0425063371658325,
      "learning_rate": 1.7280453257790367e-05,
      "loss": 2.1081,
      "step": 3800
    },
    {
      "epoch": 0.8301105724712675,
      "grad_norm": 1.419968843460083,
      "learning_rate": 1.7062540858574856e-05,
      "loss": 2.0814,
      "step": 3810
    },
    {
      "epoch": 0.8322893403780163,
      "grad_norm": 1.6163861751556396,
      "learning_rate": 1.6844628459359338e-05,
      "loss": 2.0451,
      "step": 3820
    },
    {
      "epoch": 0.8344681082847649,
      "grad_norm": 1.536008358001709,
      "learning_rate": 1.6626716060143823e-05,
      "loss": 2.1956,
      "step": 3830
    },
    {
      "epoch": 0.8366468761915137,
      "grad_norm": 1.5160956382751465,
      "learning_rate": 1.6408803660928305e-05,
      "loss": 2.1613,
      "step": 3840
    },
    {
      "epoch": 0.8388256440982624,
      "grad_norm": 3.0906758308410645,
      "learning_rate": 1.6190891261712794e-05,
      "loss": 1.9724,
      "step": 3850
    },
    {
      "epoch": 0.8410044120050112,
      "grad_norm": 2.2570366859436035,
      "learning_rate": 1.5972978862497276e-05,
      "loss": 2.1733,
      "step": 3860
    },
    {
      "epoch": 0.84318317991176,
      "grad_norm": 1.6296088695526123,
      "learning_rate": 1.575506646328176e-05,
      "loss": 2.187,
      "step": 3870
    },
    {
      "epoch": 0.8453619478185086,
      "grad_norm": 1.9797970056533813,
      "learning_rate": 1.5537154064066243e-05,
      "loss": 2.1434,
      "step": 3880
    },
    {
      "epoch": 0.8475407157252574,
      "grad_norm": 1.2197474241256714,
      "learning_rate": 1.5319241664850732e-05,
      "loss": 2.1588,
      "step": 3890
    },
    {
      "epoch": 0.8497194836320061,
      "grad_norm": 1.27677583694458,
      "learning_rate": 1.5101329265635214e-05,
      "loss": 2.0457,
      "step": 3900
    },
    {
      "epoch": 0.8518982515387549,
      "grad_norm": 1.3219400644302368,
      "learning_rate": 1.48834168664197e-05,
      "loss": 2.1473,
      "step": 3910
    },
    {
      "epoch": 0.8540770194455035,
      "grad_norm": 1.1980042457580566,
      "learning_rate": 1.4665504467204186e-05,
      "loss": 2.1774,
      "step": 3920
    },
    {
      "epoch": 0.8562557873522523,
      "grad_norm": 1.4819797277450562,
      "learning_rate": 1.4447592067988668e-05,
      "loss": 2.1542,
      "step": 3930
    },
    {
      "epoch": 0.858434555259001,
      "grad_norm": 2.352372646331787,
      "learning_rate": 1.4229679668773155e-05,
      "loss": 2.0029,
      "step": 3940
    },
    {
      "epoch": 0.8606133231657498,
      "grad_norm": 1.0400832891464233,
      "learning_rate": 1.4011767269557637e-05,
      "loss": 2.1144,
      "step": 3950
    },
    {
      "epoch": 0.8627920910724985,
      "grad_norm": 2.9133689403533936,
      "learning_rate": 1.3793854870342124e-05,
      "loss": 2.1584,
      "step": 3960
    },
    {
      "epoch": 0.8649708589792472,
      "grad_norm": 1.5255107879638672,
      "learning_rate": 1.3575942471126606e-05,
      "loss": 2.1895,
      "step": 3970
    },
    {
      "epoch": 0.867149626885996,
      "grad_norm": 2.7942111492156982,
      "learning_rate": 1.3358030071911093e-05,
      "loss": 2.1269,
      "step": 3980
    },
    {
      "epoch": 0.8693283947927447,
      "grad_norm": 2.0887558460235596,
      "learning_rate": 1.3140117672695575e-05,
      "loss": 2.2099,
      "step": 3990
    },
    {
      "epoch": 0.8715071626994935,
      "grad_norm": 1.2828164100646973,
      "learning_rate": 1.2922205273480062e-05,
      "loss": 2.0889,
      "step": 4000
    },
    {
      "epoch": 0.8736859306062422,
      "grad_norm": 1.7931259870529175,
      "learning_rate": 1.2704292874264544e-05,
      "loss": 2.21,
      "step": 4010
    },
    {
      "epoch": 0.8758646985129909,
      "grad_norm": 1.5271015167236328,
      "learning_rate": 1.2486380475049031e-05,
      "loss": 2.0303,
      "step": 4020
    },
    {
      "epoch": 0.8780434664197396,
      "grad_norm": 2.0441668033599854,
      "learning_rate": 1.2268468075833515e-05,
      "loss": 2.1822,
      "step": 4030
    },
    {
      "epoch": 0.8802222343264884,
      "grad_norm": 2.419523239135742,
      "learning_rate": 1.2050555676618e-05,
      "loss": 1.9957,
      "step": 4040
    },
    {
      "epoch": 0.8824010022332371,
      "grad_norm": 1.9003018140792847,
      "learning_rate": 1.1832643277402484e-05,
      "loss": 2.2041,
      "step": 4050
    },
    {
      "epoch": 0.8845797701399858,
      "grad_norm": 1.2739782333374023,
      "learning_rate": 1.161473087818697e-05,
      "loss": 2.1764,
      "step": 4060
    },
    {
      "epoch": 0.8867585380467345,
      "grad_norm": 1.5597190856933594,
      "learning_rate": 1.1396818478971453e-05,
      "loss": 2.2387,
      "step": 4070
    },
    {
      "epoch": 0.8889373059534833,
      "grad_norm": 1.5829212665557861,
      "learning_rate": 1.1178906079755938e-05,
      "loss": 2.0917,
      "step": 4080
    },
    {
      "epoch": 0.8911160738602321,
      "grad_norm": 2.21268367767334,
      "learning_rate": 1.0960993680540422e-05,
      "loss": 2.0563,
      "step": 4090
    },
    {
      "epoch": 0.8932948417669808,
      "grad_norm": 1.3950040340423584,
      "learning_rate": 1.0743081281324909e-05,
      "loss": 2.0998,
      "step": 4100
    },
    {
      "epoch": 0.8954736096737295,
      "grad_norm": 5.75084924697876,
      "learning_rate": 1.0525168882109393e-05,
      "loss": 1.9976,
      "step": 4110
    },
    {
      "epoch": 0.8976523775804782,
      "grad_norm": 1.7106778621673584,
      "learning_rate": 1.0307256482893878e-05,
      "loss": 2.1093,
      "step": 4120
    },
    {
      "epoch": 0.899831145487227,
      "grad_norm": 2.030909538269043,
      "learning_rate": 1.0111135323599913e-05,
      "loss": 1.9795,
      "step": 4130
    },
    {
      "epoch": 0.9020099133939757,
      "grad_norm": 2.027991771697998,
      "learning_rate": 9.893222924384398e-06,
      "loss": 2.1862,
      "step": 4140
    },
    {
      "epoch": 0.9041886813007245,
      "grad_norm": 1.5966559648513794,
      "learning_rate": 9.675310525168882e-06,
      "loss": 2.1593,
      "step": 4150
    },
    {
      "epoch": 0.9063674492074731,
      "grad_norm": 2.012355089187622,
      "learning_rate": 9.457398125953367e-06,
      "loss": 2.2358,
      "step": 4160
    },
    {
      "epoch": 0.9085462171142219,
      "grad_norm": 1.1290843486785889,
      "learning_rate": 9.239485726737852e-06,
      "loss": 1.9804,
      "step": 4170
    },
    {
      "epoch": 0.9107249850209707,
      "grad_norm": 1.9528999328613281,
      "learning_rate": 9.021573327522336e-06,
      "loss": 1.9815,
      "step": 4180
    },
    {
      "epoch": 0.9129037529277194,
      "grad_norm": 1.3992676734924316,
      "learning_rate": 8.803660928306821e-06,
      "loss": 2.2303,
      "step": 4190
    },
    {
      "epoch": 0.9150825208344681,
      "grad_norm": 2.7588536739349365,
      "learning_rate": 8.585748529091305e-06,
      "loss": 1.9759,
      "step": 4200
    },
    {
      "epoch": 0.9172612887412168,
      "grad_norm": 1.2312101125717163,
      "learning_rate": 8.36783612987579e-06,
      "loss": 1.9346,
      "step": 4210
    },
    {
      "epoch": 0.9194400566479656,
      "grad_norm": 1.414725422859192,
      "learning_rate": 8.149923730660276e-06,
      "loss": 2.1599,
      "step": 4220
    },
    {
      "epoch": 0.9216188245547143,
      "grad_norm": 1.9410115480422974,
      "learning_rate": 7.93201133144476e-06,
      "loss": 2.2922,
      "step": 4230
    },
    {
      "epoch": 0.9237975924614631,
      "grad_norm": 1.3810031414031982,
      "learning_rate": 7.714098932229245e-06,
      "loss": 2.1357,
      "step": 4240
    },
    {
      "epoch": 0.9259763603682117,
      "grad_norm": 2.286970615386963,
      "learning_rate": 7.496186533013728e-06,
      "loss": 2.2091,
      "step": 4250
    },
    {
      "epoch": 0.9281551282749605,
      "grad_norm": 1.7349565029144287,
      "learning_rate": 7.278274133798213e-06,
      "loss": 2.2703,
      "step": 4260
    },
    {
      "epoch": 0.9303338961817093,
      "grad_norm": 1.2322008609771729,
      "learning_rate": 7.060361734582697e-06,
      "loss": 2.13,
      "step": 4270
    },
    {
      "epoch": 0.932512664088458,
      "grad_norm": 1.713185429573059,
      "learning_rate": 6.8424493353671835e-06,
      "loss": 2.2797,
      "step": 4280
    },
    {
      "epoch": 0.9346914319952067,
      "grad_norm": 1.346706748008728,
      "learning_rate": 6.624536936151668e-06,
      "loss": 2.1349,
      "step": 4290
    },
    {
      "epoch": 0.9368701999019554,
      "grad_norm": 1.585147738456726,
      "learning_rate": 6.4066245369361525e-06,
      "loss": 2.0166,
      "step": 4300
    },
    {
      "epoch": 0.9390489678087042,
      "grad_norm": 2.7959702014923096,
      "learning_rate": 6.188712137720636e-06,
      "loss": 2.1012,
      "step": 4310
    },
    {
      "epoch": 0.9412277357154529,
      "grad_norm": 1.1918491125106812,
      "learning_rate": 5.9707997385051215e-06,
      "loss": 2.2365,
      "step": 4320
    },
    {
      "epoch": 0.9434065036222017,
      "grad_norm": 2.0239815711975098,
      "learning_rate": 5.752887339289606e-06,
      "loss": 2.0235,
      "step": 4330
    },
    {
      "epoch": 0.9455852715289503,
      "grad_norm": 2.168337821960449,
      "learning_rate": 5.5349749400740905e-06,
      "loss": 2.203,
      "step": 4340
    },
    {
      "epoch": 0.9477640394356991,
      "grad_norm": 1.529371976852417,
      "learning_rate": 5.317062540858575e-06,
      "loss": 2.0359,
      "step": 4350
    },
    {
      "epoch": 0.9499428073424478,
      "grad_norm": 1.4208890199661255,
      "learning_rate": 5.0991501416430595e-06,
      "loss": 2.1041,
      "step": 4360
    },
    {
      "epoch": 0.9521215752491966,
      "grad_norm": 1.7850455045700073,
      "learning_rate": 4.881237742427544e-06,
      "loss": 1.9441,
      "step": 4370
    },
    {
      "epoch": 0.9543003431559454,
      "grad_norm": 2.074185609817505,
      "learning_rate": 4.663325343212029e-06,
      "loss": 2.1526,
      "step": 4380
    },
    {
      "epoch": 0.956479111062694,
      "grad_norm": 1.5893774032592773,
      "learning_rate": 4.445412943996514e-06,
      "loss": 1.8665,
      "step": 4390
    },
    {
      "epoch": 0.9586578789694428,
      "grad_norm": 3.2709412574768066,
      "learning_rate": 4.227500544780998e-06,
      "loss": 2.0364,
      "step": 4400
    },
    {
      "epoch": 0.9608366468761915,
      "grad_norm": 1.4731512069702148,
      "learning_rate": 4.009588145565483e-06,
      "loss": 2.1414,
      "step": 4410
    },
    {
      "epoch": 0.9630154147829403,
      "grad_norm": 2.498953104019165,
      "learning_rate": 3.7916757463499673e-06,
      "loss": 2.1499,
      "step": 4420
    },
    {
      "epoch": 0.9651941826896889,
      "grad_norm": 2.672210216522217,
      "learning_rate": 3.5737633471344518e-06,
      "loss": 2.1379,
      "step": 4430
    },
    {
      "epoch": 0.9673729505964377,
      "grad_norm": 2.133305311203003,
      "learning_rate": 3.355850947918937e-06,
      "loss": 2.0917,
      "step": 4440
    },
    {
      "epoch": 0.9695517185031864,
      "grad_norm": 1.711329698562622,
      "learning_rate": 3.1379385487034216e-06,
      "loss": 2.247,
      "step": 4450
    },
    {
      "epoch": 0.9717304864099352,
      "grad_norm": 1.9513622522354126,
      "learning_rate": 2.920026149487906e-06,
      "loss": 2.0453,
      "step": 4460
    },
    {
      "epoch": 0.973909254316684,
      "grad_norm": 1.6280027627944946,
      "learning_rate": 2.7021137502723906e-06,
      "loss": 2.1394,
      "step": 4470
    },
    {
      "epoch": 0.9760880222234326,
      "grad_norm": 1.7284955978393555,
      "learning_rate": 2.484201351056875e-06,
      "loss": 1.9804,
      "step": 4480
    },
    {
      "epoch": 0.9782667901301814,
      "grad_norm": 6.124330520629883,
      "learning_rate": 2.26628895184136e-06,
      "loss": 2.147,
      "step": 4490
    },
    {
      "epoch": 0.9804455580369301,
      "grad_norm": 1.946187973022461,
      "learning_rate": 2.0483765526258445e-06,
      "loss": 2.1095,
      "step": 4500
    },
    {
      "epoch": 0.9826243259436789,
      "grad_norm": 1.2501169443130493,
      "learning_rate": 1.830464153410329e-06,
      "loss": 2.1882,
      "step": 4510
    },
    {
      "epoch": 0.9848030938504276,
      "grad_norm": 1.310221791267395,
      "learning_rate": 1.612551754194814e-06,
      "loss": 2.1211,
      "step": 4520
    },
    {
      "epoch": 0.9869818617571763,
      "grad_norm": 2.6492578983306885,
      "learning_rate": 1.3946393549792984e-06,
      "loss": 2.0502,
      "step": 4530
    },
    {
      "epoch": 0.989160629663925,
      "grad_norm": 1.3899654150009155,
      "learning_rate": 1.176726955763783e-06,
      "loss": 1.9565,
      "step": 4540
    },
    {
      "epoch": 0.9913393975706738,
      "grad_norm": 2.735801935195923,
      "learning_rate": 9.588145565482676e-07,
      "loss": 2.1606,
      "step": 4550
    },
    {
      "epoch": 0.9935181654774226,
      "grad_norm": 1.7211549282073975,
      "learning_rate": 7.409021573327523e-07,
      "loss": 2.1654,
      "step": 4560
    },
    {
      "epoch": 0.9956969333841712,
      "grad_norm": 1.5029598474502563,
      "learning_rate": 5.229897581172369e-07,
      "loss": 2.0732,
      "step": 4570
    },
    {
      "epoch": 0.99787570129092,
      "grad_norm": 2.3289270401000977,
      "learning_rate": 3.050773589017215e-07,
      "loss": 2.1393,
      "step": 4580
    }
  ],
  "logging_steps": 10,
  "max_steps": 4589,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.866086685607035e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
